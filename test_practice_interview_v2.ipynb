{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession,Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/26 11:57:16 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/05/26 11:57:16 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/05/26 11:57:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/05/26 11:57:16 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.\\\n",
    "    appName(\"Practice\").\\\n",
    "        getOrCreate()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "employees_df =spark.read.format(\"csv\").\\\n",
    "    option(\"header\",\"true\").\\\n",
    "        option(\"inferschema\",\"true\").\\\n",
    "            option(\"mode\",\"PERMISSIVE\").\\\n",
    "                load(\"/user/sovik/employees.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Nominee: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_df.createOrReplaceTempView(\"Emp_temp_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+------+-------+--------------------------+---------+\n",
      "|ID |Name           |Salary|Country|Address                   |Nominee  |\n",
      "+---+---------------+------+-------+--------------------------+---------+\n",
      "|2  |Jane Smith     |60000 |Canada |456 Maple St Oaktown CA   |Nominee2 |\n",
      "|6  |Ava Martinez   |75000 |Canada |303 Birch St Mapletown CA |Nominee6 |\n",
      "|10 |Sophia Taylor  |80000 |Canada |707 Cherry St Hillside CA |Nominee10|\n",
      "|14 |Mia Harris     |78000 |Canada |222 Maple St Mountview CA |Nominee14|\n",
      "|18 |Amelia Hall    |85000 |Canada |666 Spruce St Highland CA |Nominee18|\n",
      "|22 |Charlotte Scott|90000 |Canada |123 Main St Snowtown CA   |Nominee22|\n",
      "|26 |Sophia Nelson  |74000 |Canada |567 Maple St Northwood CA |Nominee26|\n",
      "|30 |Ella Roberts   |80000 |Canada |901 Spruce St Woodlands CA|Nominee30|\n",
      "+---+---------------+------+-------+--------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          \n",
    "          Select * from Emp_temp_view where Country ='Canada'\n",
    "          \n",
    "          \"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+\n",
      "|Employee_id|  Employee_name|\n",
      "+-----------+---------------+\n",
      "|          1|       John Doe|\n",
      "|          2|     Jane Smith|\n",
      "|          3|      Jim Brown|\n",
      "|          4|     Emma Davis|\n",
      "|          5|   Liam Johnson|\n",
      "|          6|   Ava Martinez|\n",
      "|          7|    Noah Miller|\n",
      "|          8|     Mia Wilson|\n",
      "|          9|  William Moore|\n",
      "|         10|  Sophia Taylor|\n",
      "|         11| Mason Anderson|\n",
      "|         12|Isabella Thomas|\n",
      "|         13|    Jacob White|\n",
      "|         14|     Mia Harris|\n",
      "|         15|    Ethan Clark|\n",
      "|         16|   Olivia Lewis|\n",
      "|         17|   Lucas Walker|\n",
      "|         18|    Amelia Hall|\n",
      "|         19|    Henry Young|\n",
      "|         20|       Ava King|\n",
      "+-----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.select(col(\"ID\").alias(\"Employee_id\"),employees_df.Name.alias(\"Employee_name\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets add quebecoise as name to whoever is living in Maple St in Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "quebeqoise_employee_df=employees_df.select(col(\"*\"),lit(\"Quebeqoise\").alias(\"quebeqise_name\")).where(\"address like '%Maple St%' and country = 'Canada'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------+-------+-------------------------+---------+--------------+\n",
      "|ID |Name         |Salary|Country|Address                  |Nominee  |quebeqise_name|\n",
      "+---+-------------+------+-------+-------------------------+---------+--------------+\n",
      "|2  |Jane Smith   |60000 |Canada |456 Maple St Oaktown CA  |Nominee2 |Quebeqoise    |\n",
      "|14 |Mia Harris   |78000 |Canada |222 Maple St Mountview CA|Nominee14|Quebeqoise    |\n",
      "|26 |Sophia Nelson|74000 |Canada |567 Maple St Northwood CA|Nominee26|Quebeqoise    |\n",
      "+---+-------------+------+-------+-------------------------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "quebeqoise_employee_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `quebeqoise_name` cannot be resolved. Did you mean one of the following? [`quebeqise_name`, `Name`, `Nominee`, `Address`, `Country`].;\n'Project [ID#105, Name#106, Salary#107, Country#108, Address#109, Nominee#110, quebeqise_name#309, concat(Name#106, 'quebeqoise_name) AS real_quebeqoise_name#389]\n+- Filter (address#109 LIKE %Maple St% AND (country#108 = Canada))\n   +- Project [ID#105, Name#106, Salary#107, Country#108, Address#109, Nominee#110, Quebeqoise AS quebeqise_name#309]\n      +- Relation [ID#105,Name#106,Salary#107,Country#108,Address#109,Nominee#110] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m employee_df_with_quebeqoise \u001b[38;5;241m=\u001b[39m \u001b[43mquebeqoise_employee_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquebeqoise_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreal_quebeqoise_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py:3223\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   3178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   3179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   3180\u001b[0m \n\u001b[1;32m   3181\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3221\u001b[0m \u001b[38;5;124;03m    +-----+---+\u001b[39;00m\n\u001b[1;32m   3222\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3223\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m/opt/conda/default/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `quebeqoise_name` cannot be resolved. Did you mean one of the following? [`quebeqise_name`, `Name`, `Nominee`, `Address`, `Country`].;\n'Project [ID#105, Name#106, Salary#107, Country#108, Address#109, Nominee#110, quebeqise_name#309, concat(Name#106, 'quebeqoise_name) AS real_quebeqoise_name#389]\n+- Filter (address#109 LIKE %Maple St% AND (country#108 = Canada))\n   +- Project [ID#105, Name#106, Salary#107, Country#108, Address#109, Nominee#110, Quebeqoise AS quebeqise_name#309]\n      +- Relation [ID#105,Name#106,Salary#107,Country#108,Address#109,Nominee#110] csv\n"
     ]
    }
   ],
   "source": [
    "employee_df_with_quebeqoise = quebeqoise_employee_df.withColumn(\"any_name\",when(concat(col(\"Name\"), col(\"quebeqoise_name\")).alias(\"real_quebeqoise_name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_data = [(1,'manish',50000,'IT','m'),\n",
    "(2,'vikash',60000,'sales','m'),\n",
    "(3,'raushan',70000,'marketing','m'),\n",
    "(4,'mukesh',80000,'IT','m'),\n",
    "(5,'priti',90000,'sales','f'),\n",
    "(6,'nikita',45000,'marketing','f'),\n",
    "(7,'ragini',55000,'marketing','f'),\n",
    "(8,'rashi',100000,'IT','f'),\n",
    "(9,'aditya',65000,'IT','m'),\n",
    "(10,'rahul',50000,'marketing','m'),\n",
    "(11,'rakhi',50000,'IT','f'),\n",
    "(12,'akhilesh',90000,'sales','m')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_schema=['id','name','sal','dept','sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_emp=spark.createDataFrame(emp_data,schema=my_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---------+---+\n",
      "| id|    name|   sal|     dept|sex|\n",
      "+---+--------+------+---------+---+\n",
      "|  1|  manish| 50000|       IT|  m|\n",
      "|  2|  vikash| 60000|    sales|  m|\n",
      "|  3| raushan| 70000|marketing|  m|\n",
      "|  4|  mukesh| 80000|       IT|  m|\n",
      "|  5|   priti| 90000|    sales|  f|\n",
      "|  6|  nikita| 45000|marketing|  f|\n",
      "|  7|  ragini| 55000|marketing|  f|\n",
      "|  8|   rashi|100000|       IT|  f|\n",
      "|  9|  aditya| 65000|       IT|  m|\n",
      "| 10|   rahul| 50000|marketing|  m|\n",
      "| 11|   rakhi| 50000|       IT|  f|\n",
      "| 12|akhilesh| 90000|    sales|  m|\n",
      "+---+--------+------+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec=Window.partitionBy(col(\"dept\")).orderBy(col(\"sal\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec_totsal=Window.partitionBy(col(\"dept\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_df=my_emp.withColumn(\"rank_sal_by_dept\",row_number().over(window_spec) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_df_tot_sal=my_emp.withColumn(\"total_sal\",sum(col(\"sal\")).over(window_spec_totsal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---------+---+---------+\n",
      "| id|    name|   sal|     dept|sex|total_sal|\n",
      "+---+--------+------+---------+---+---------+\n",
      "|  1|  manish| 50000|       IT|  m|   345000|\n",
      "|  4|  mukesh| 80000|       IT|  m|   345000|\n",
      "|  8|   rashi|100000|       IT|  f|   345000|\n",
      "|  9|  aditya| 65000|       IT|  m|   345000|\n",
      "| 11|   rakhi| 50000|       IT|  f|   345000|\n",
      "|  3| raushan| 70000|marketing|  m|   220000|\n",
      "|  6|  nikita| 45000|marketing|  f|   220000|\n",
      "|  7|  ragini| 55000|marketing|  f|   220000|\n",
      "| 10|   rahul| 50000|marketing|  m|   220000|\n",
      "|  2|  vikash| 60000|    sales|  m|   240000|\n",
      "|  5|   priti| 90000|    sales|  f|   240000|\n",
      "| 12|akhilesh| 90000|    sales|  m|   240000|\n",
      "+---+--------+------+---------+---+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "intermediate_df_tot_sal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---------+---+----------------+\n",
      "| id|    name|   sal|     dept|sex|rank_sal_by_dept|\n",
      "+---+--------+------+---------+---+----------------+\n",
      "|  8|   rashi|100000|       IT|  f|               1|\n",
      "|  4|  mukesh| 80000|       IT|  m|               2|\n",
      "|  3| raushan| 70000|marketing|  m|               1|\n",
      "|  7|  ragini| 55000|marketing|  f|               2|\n",
      "|  5|   priti| 90000|    sales|  f|               1|\n",
      "| 12|akhilesh| 90000|    sales|  m|               2|\n",
      "+---+--------+------+---------+---+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "intermediate_df.filter(col(\"rank_sal_by_dept\")<=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-----------+\n",
      "|product_id|product_name| sale_date|sale_amount|\n",
      "+----------+------------+----------+-----------+\n",
      "|         1|      iphone|01-01-2023|    1500000|\n",
      "|         2|     samsung|01-01-2023|    1100000|\n",
      "|         3|     oneplus|01-01-2023|    1100000|\n",
      "|         1|      iphone|01-02-2023|    1300000|\n",
      "|         2|     samsung|01-02-2023|    1120000|\n",
      "|         3|     oneplus|01-02-2023|    1120000|\n",
      "|         1|      iphone|01-03-2023|    1600000|\n",
      "|         2|     samsung|01-03-2023|    1080000|\n",
      "|         3|     oneplus|01-03-2023|    1160000|\n",
      "|         1|      iphone|01-04-2023|    1700000|\n",
      "|         2|     samsung|01-04-2023|    1800000|\n",
      "|         3|     oneplus|01-04-2023|    1170000|\n",
      "|         1|      iphone|01-05-2023|    1200000|\n",
      "|         2|     samsung|01-05-2023|     980000|\n",
      "|         3|     oneplus|01-05-2023|    1175000|\n",
      "|         1|      iphone|01-06-2023|    1100000|\n",
      "|         2|     samsung|01-06-2023|    1100000|\n",
      "|         3|     oneplus|01-06-2023|    1200000|\n",
      "+----------+------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_data = [\n",
    "(1,\"iphone\",\"01-01-2023\",1500000),\n",
    "(2,\"samsung\",\"01-01-2023\",1100000),\n",
    "(3,\"oneplus\",\"01-01-2023\",1100000),\n",
    "(1,\"iphone\",\"01-02-2023\",1300000),\n",
    "(2,\"samsung\",\"01-02-2023\",1120000),\n",
    "(3,\"oneplus\",\"01-02-2023\",1120000),\n",
    "(1,\"iphone\",\"01-03-2023\",1600000),\n",
    "(2,\"samsung\",\"01-03-2023\",1080000),\n",
    "(3,\"oneplus\",\"01-03-2023\",1160000),\n",
    "(1,\"iphone\",\"01-04-2023\",1700000),\n",
    "(2,\"samsung\",\"01-04-2023\",1800000),\n",
    "(3,\"oneplus\",\"01-04-2023\",1170000),\n",
    "(1,\"iphone\",\"01-05-2023\",1200000),\n",
    "(2,\"samsung\",\"01-05-2023\",980000),\n",
    "(3,\"oneplus\",\"01-05-2023\",1175000),\n",
    "(1,\"iphone\",\"01-06-2023\",1100000),\n",
    "(2,\"samsung\",\"01-06-2023\",1100000),\n",
    "(3,\"oneplus\",\"01-06-2023\",1200000)\n",
    "]\n",
    "\n",
    "product_schema=['product_id',\"product_name\",\"sale_date\",\"sale_amount\"]\n",
    "\n",
    "product_df=spark.createDataFrame(product_data,product_schema)\n",
    "\n",
    "product_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the percentage of loss or gain depending on previous month sale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_spec=Window.partitionBy(col(\"product_name\")).orderBy(\"sale_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-----------+-------------------+\n",
      "|product_id|product_name| sale_date|sale_amount|previous_month_sale|\n",
      "+----------+------------+----------+-----------+-------------------+\n",
      "|         1|      iphone|01-01-2023|    1500000|                  0|\n",
      "|         1|      iphone|01-02-2023|    1300000|            1500000|\n",
      "|         1|      iphone|01-03-2023|    1600000|            1300000|\n",
      "|         1|      iphone|01-04-2023|    1700000|            1600000|\n",
      "|         1|      iphone|01-05-2023|    1200000|            1700000|\n",
      "|         1|      iphone|01-06-2023|    1100000|            1200000|\n",
      "|         3|     oneplus|01-01-2023|    1100000|                  0|\n",
      "|         3|     oneplus|01-02-2023|    1120000|            1100000|\n",
      "|         3|     oneplus|01-03-2023|    1160000|            1120000|\n",
      "|         3|     oneplus|01-04-2023|    1170000|            1160000|\n",
      "|         3|     oneplus|01-05-2023|    1175000|            1170000|\n",
      "|         3|     oneplus|01-06-2023|    1200000|            1175000|\n",
      "|         2|     samsung|01-01-2023|    1100000|                  0|\n",
      "|         2|     samsung|01-02-2023|    1120000|            1100000|\n",
      "|         2|     samsung|01-03-2023|    1080000|            1120000|\n",
      "|         2|     samsung|01-04-2023|    1800000|            1080000|\n",
      "|         2|     samsung|01-05-2023|     980000|            1800000|\n",
      "|         2|     samsung|01-06-2023|    1100000|             980000|\n",
      "+----------+------------+----------+-----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_df_with_lag=product_df.withColumn(\"previous_month_sale\",lag(col(\"sale_amount\"),1,0).over(product_spec))\n",
    "#product_df_with_lag_final=product_df_with_lag.withColumn(\"previous_month_sale\",when(isnull(col(\"previous_month_sale\")),0).otherwise(col(\"previous_month_sale\")) )\n",
    "product_df_with_lag.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df_with_lag_final_vf = product_df_with_lag.withColumn(\n",
    "    \"profit_by_over_previous_month\",\n",
    "    round(\n",
    "        when(col(\"previous_month_sale\") != 0, \n",
    "             ((col(\"sale_amount\") - col(\"previous_month_sale\")) * 100) / col(\"previous_month_sale\"))\n",
    "        .otherwise(\"NA\"), 2\n",
    "    )\n",
    ")\n",
    "product_df_with_lag_final_vf2 = product_df_with_lag_final_vf.withColumn(\n",
    "    \"profit_by_over_previous_month\",\n",
    "    when(col(\"profit_by_over_previous_month\").isNull(), \"NA\")\n",
    "    .otherwise(col(\"profit_by_over_previous_month\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-----------+-------------------+-----------------------------+\n",
      "|product_id|product_name| sale_date|sale_amount|previous_month_sale|profit_by_over_previous_month|\n",
      "+----------+------------+----------+-----------+-------------------+-----------------------------+\n",
      "|         1|      iphone|01-01-2023|    1500000|                  0|                           NA|\n",
      "|         1|      iphone|01-02-2023|    1300000|            1500000|                       -13.33|\n",
      "|         1|      iphone|01-03-2023|    1600000|            1300000|                        23.08|\n",
      "|         1|      iphone|01-04-2023|    1700000|            1600000|                         6.25|\n",
      "|         1|      iphone|01-05-2023|    1200000|            1700000|                       -29.41|\n",
      "|         1|      iphone|01-06-2023|    1100000|            1200000|                        -8.33|\n",
      "|         3|     oneplus|01-01-2023|    1100000|                  0|                           NA|\n",
      "|         3|     oneplus|01-02-2023|    1120000|            1100000|                         1.82|\n",
      "|         3|     oneplus|01-03-2023|    1160000|            1120000|                         3.57|\n",
      "|         3|     oneplus|01-04-2023|    1170000|            1160000|                         0.86|\n",
      "|         3|     oneplus|01-05-2023|    1175000|            1170000|                         0.43|\n",
      "|         3|     oneplus|01-06-2023|    1200000|            1175000|                         2.13|\n",
      "|         2|     samsung|01-01-2023|    1100000|                  0|                           NA|\n",
      "|         2|     samsung|01-02-2023|    1120000|            1100000|                         1.82|\n",
      "|         2|     samsung|01-03-2023|    1080000|            1120000|                        -3.57|\n",
      "|         2|     samsung|01-04-2023|    1800000|            1080000|                        66.67|\n",
      "|         2|     samsung|01-05-2023|     980000|            1800000|                       -45.56|\n",
      "|         2|     samsung|01-06-2023|    1100000|             980000|                        12.24|\n",
      "+----------+------------+----------+-----------+-------------------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_df_with_lag_final_vf2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbounded preceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_spec_unbounded_following=Window.partitionBy(col(\"product_name\")).orderBy(col(\"sale_amount\")).\\\n",
    "    rangeBetween(Window.unboundedPreceding,Window.unboundedFollowing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-----------+---------------+--------------+\n",
      "|product_id|product_name| sale_date|sale_amount|first_sales_amt|last_sales_amt|\n",
      "+----------+------------+----------+-----------+---------------+--------------+\n",
      "|         1|      iphone|01-06-2023|    1100000|        1100000|       1700000|\n",
      "|         1|      iphone|01-05-2023|    1200000|        1100000|       1700000|\n",
      "|         1|      iphone|01-02-2023|    1300000|        1100000|       1700000|\n",
      "|         1|      iphone|01-01-2023|    1500000|        1100000|       1700000|\n",
      "|         1|      iphone|01-03-2023|    1600000|        1100000|       1700000|\n",
      "|         1|      iphone|01-04-2023|    1700000|        1100000|       1700000|\n",
      "|         3|     oneplus|01-01-2023|    1100000|        1100000|       1200000|\n",
      "|         3|     oneplus|01-02-2023|    1120000|        1100000|       1200000|\n",
      "|         3|     oneplus|01-03-2023|    1160000|        1100000|       1200000|\n",
      "|         3|     oneplus|01-04-2023|    1170000|        1100000|       1200000|\n",
      "|         3|     oneplus|01-05-2023|    1175000|        1100000|       1200000|\n",
      "|         3|     oneplus|01-06-2023|    1200000|        1100000|       1200000|\n",
      "|         2|     samsung|01-05-2023|     980000|         980000|       1800000|\n",
      "|         2|     samsung|01-03-2023|    1080000|         980000|       1800000|\n",
      "|         2|     samsung|01-01-2023|    1100000|         980000|       1800000|\n",
      "|         2|     samsung|01-06-2023|    1100000|         980000|       1800000|\n",
      "|         2|     samsung|01-02-2023|    1120000|         980000|       1800000|\n",
      "|         2|     samsung|01-04-2023|    1800000|         980000|       1800000|\n",
      "+----------+------------+----------+-----------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_df.withColumn(\"first_sales_amt\",first(col(\"sale_amount\")).over(product_spec_unbounded_following)).\\\n",
    "    withColumn(\"last_sales_amt\",last(col(\"sale_amount\")).over(product_spec_unbounded_following)).\\\n",
    "        show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
